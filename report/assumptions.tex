In this section we will summarize the assumptions for this project, emerged during the several meetings.
\begin{itemize}
	\item{We are not interested to study how sequential algorithms behave. We care only about the parallel part of our algorithms. The sequential part is always implemented using the \textit{qsort} POSIX standard function, and it does not matter if it works on primary memory only, rather than on secondary one. Sequential and parallel sorting are completely disjoint operations, which can be studied separately.}
	\item{Some algorithms natively begin, or end, with data centralized in a single process, while others begin or end with data distributed among all processes. For example mergesort begins with data distributed: any process sorts its piece fo data, and send it to another node that takes care of merging it, in order to end with data centralized on a single process. Quicksort, at the opposite, start with centralized data; the first process splits data and sends it to the other, in order to end up with distributed sorted data. For this reason and to mantain some homogenity among the algorithms we chose to always begin and end with centralized data. The algorithms that begin or end with distributed data will take care of scattering or gathering data, studying these extra (ie: unneeded by the algorithm, but needed by our common algorithm-testbed) operations separately from the rest of the computation.}
	\item{Since our platform is a clusted made of multicore nodes, we know that communication patterns between our several processes may weight a lot on the final performances. We will be looking for heuristical approaches to map processes in order to study what scenario will result in best performances due to communications between cores on different nodes, or on different parts of the single node.}
\end{itemize}
