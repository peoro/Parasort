\label{DAL}
Our algorithms must be able to handle big data set to some extent, for example we can easily think of a scenario where each core has to sort half a gigabyte of data, and we are using 256 cores; the total memory used, among the whole system, is 128 gigabytes of data.
At least the first phases of any algorithm (before data is fully distributed), and the last phases (while data is getting gathered) will have for sure to support datasets that cannot fit in main memory, and will be forced to run their computations on some files allocated in secondary memory.
This is a big issue, since it would force us to explicitly re-design any algorithm in order to make it handle both the mediums data could be stored in.
In order to limit the complexity of algorithms we decided to separate medium handling from actual algorithm code, thus creating a new abstraction layer in our application model.

At this purpose we decided to add a further abstraction layer below the actual Sorting Framework: we introduced a new data structure called \texttt{Data} that represents a dataset independently on its form or position: it can represent both an array allocated on principal memory or a file allocated on the hard disk, and it has been thought to be able to represent even other kind of data representation (eg: a compressed dataset). Both Sorting Algorithm and Sorting Framework, which are at a higher abstraction level, do not need to know about how or where \texttt{Data} is allocated, and use it in a transparent way.
We needed to write some kind of run-time support for the Sorting levels, which is logically placed just below the Sorting Framework: since we want to save the algorithm from actually care about how Data is allocated, Sorting Algorithm needs to use some functions that will take care of it exposing a data-independent signature. Our rule of thumb is that all and only the functions logically placed at this abstraction level are the only ones actually working with a \texttt{Data} object (ie: accessing its field directly or indirectly) and vice-versa.
Functions at the DAL level will one (or more) \texttt{Data} object, will see whether it's allocated on primary or secondary memory, and according to this they'll run some data-dependent codes, optimized for the medium where the \texttt{Data} object is allocated.

\subsection*{Data Abstraction Layer - API}
\texttt{Data} is the key datatype of the DAL. Designing a Sorting Algorithm does not require to know the internal structure of \texttt{Data}, but just what it represent: a sequence of elements. Indeed, all the processes of a Sorting Algorithm declare their own \texttt{Data} (eventually more than one, depending on the specific algorithm) which will be passed as parameter to the functions of the DAL's API. To initialize and destroy a \texttt{Data} we provide two specific functions:
\begin{lstlisting}
void DAL_init( Data *data )
void DAL_destroy( Data *data )
\end{lstlisting}
Obviously, processes of a Sorting Algorithm have to collaborate somehow: DAL provides them with a set of communication primitives. The most important ones are:
\begin{lstlisting}
void DAL_send( Data *data, int dest )
void DAL_receive( Data *data, long size, int source )
void DAL_scatter( Data *data, long size, int root )
void DAL_gather( Data *data, long size, int root )
void DAL_alltoallv( Data *sendData, long *sendSizes, long *sdispls, long *recvSizes, long *rdispls )
\end{lstlisting}
The semantic of these functions is the same of the ones provided by MPI having analogous name. Notice that all the processes of the Sorting Algorithm, except the one of Rank $0$, starts with an empty \texttt{Data}, as consequence of the choice of starting with a centralized data set (see~\ref{assumptions}). Anyway, a very simple way to initialize \texttt{Data} to all processes is to perform an initial scatter of the data set.

There are other functions that need to access \texttt{Data}; these functions, with respect to the ones described above, are not related to the DAL itself, but rather to the Sorting Algorithms. Just as example, think to the function $merge$, needed to merge two input \texttt{Data} into another \texttt{Data}. It is true that $merge$ is a function related to specific algorithms, but, on the other hand, it needs to break the abstraction of \texttt{Data} in order to be implmented. TODO

\subsection*{Data Abstraction Layer - Implementation}
The type \texttt{Data} is implemented as follows:
\begin{lstlisting}
typedef struct
{
	enum Medium {
		NoMedium = 0,
		File = 1,
		Array = 2
	} medium;
	
	union
	{
		struct
		{
			int *data;
			long size;
		} array;
		struct
		{
			char name[128];
		} file;
	};
	
} Data;
\end{lstlisting}
Depending on the value of $medium$, a \texttt{Data} represents a sequence of elements that are currently being stored in main memory ($Array$), on disk ($File$) or not initialized yet ($NoMedium$). At this purpose, an $union$ is used to reflect the fact that \texttt{Data} is a generic type.  As we have already said, a \texttt{Data} is normally accessed and manipulated by the functions of the API illustrated in the previous section. Anyway, looking at the code, it is likely to encounter other functions (that substantially act like macros) which address specific purposes: 
\begin{lstlisting}
bool DAL_allocArray( Data *data, int size )
bool DAL_reallocArray ( Data *data, int size )
\end{lstlisting}
The semantic of these functions follow directly from their signature. The $DAL\_allocArray$ tries to allocate a block of $size$ integers in main memory. The $DAL\_reallocArray$ simply resize a \texttt{Data} preserving its contents; notice that a call to this function may cause the change of the medium. 

To give an idea of how we implemented the DAL's API functions (and so, how a \texttt{Data} is manipulated), we focus on the specific case of the primitive $send$. For implementing all other primitives we adopted a very similar approach; anyway, notice that other functions, like the $AllToAll$, are really trickier than the $send$. 
\begin{lstlisting}
void DAL_send( ..., Data *data, int dest )
{
	switch( data->medium ) {
		case File: {
			UNSUPPORTED_DATA( data );
			break;
		}
		case Array: {
			MPI_Send( data->array.data, data->array.size, MPI_INT, dest, 0, MPI_COMM_WORLD );
			break;
		}
		default:
			UNSUPPORTED_DATA( data );
	}
}
\end{lstlisting}
Depending on the medium where the block of data is stored, different actions are performed. In the medium is the main memory, than a simple call to a primitive of the lower level is enaugh (ie MPI$\_$Send). On the other hand, ... TODO. Notice that in both cases, a first ... TODO (suppongo si debba preliminarmente dire con una MPISend se mi appresto a invi√† dati ''secchi'' o se la roba era su file..in modo tale che la DALreceive si comporti di conseguenza).
%\subsubsection*{TODO}
%Di che altro c'e' da parlare?
%\begin{itemize}
%	\item{Come funziona piu' nel dettaglio il framework e/o gli algoritmi tenendo conto del data?}
%	\item{Come sono implementati (in via generale/con quale logica -- e/o anche nello specifico) gli algoritmi al livello data?}
%	\item{Il fatto che abbiamo dovuto astrarre MPI?}
%	\item{DOBBIAMO far capire che sta cosa non e' banale, che c'e' costata sangue! non sono riuscito ad essere meno mite di quant'ho scritto...}
%\end{itemize}


